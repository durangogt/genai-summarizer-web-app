# GitHub Models Configuration
GITHUB_TOKEN=your-github-token-here
GITHUB_MODELS_ENDPOINT=https://models.inference.ai.azure.com
# Available models with "low" or "high" rate limits (widely accessible):
#   - openai/gpt-4o-mini (recommended for cost-efficiency)
#   - openai/gpt-4.1-mini (newer, cost-efficient)
#   - openai/gpt-4o (higher quality)
#   - openai/gpt-4.1 (newest, highest quality)
# Models with "custom" tier may require special access (e.g., gpt-5-mini)
# Currently only "gpt-4o" - works
GITHUB_MODEL_NAME="gpt-4o"

# JWT Authentication
SECRET_KEY=your-secret-key-change-this-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=60

# Server Configuration
HOST=127.0.0.1
PORT=8000

# File Upload Limits
MAX_FILE_SIZE_MB=10
MAX_BATCH_FILES=10

# Network Configuration
# Set to true to verify SSL certificates (recommended for production)
# Set to false to disable SSL verification (useful in corporate environments with proxy/firewall)
VERIFY_SSL_CERTIFICATES=false
URL_FETCH_TIMEOUT=10

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log
